{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OPC"
      ],
      "metadata": {
        "id": "paVkFW-qwi2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JAYtyo4oqizU",
        "outputId": "d0b38aa5-b0a3-4cd0-cba1-57639a1a2ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b687448b194f4801a971654113b2a5e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost==1.2.7\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (1.24.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost==1.2.7) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost==1.2.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost==1.2.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost==1.2.7) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost==1.2.7) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost==1.2.7) (9.1.2)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install compatible versions\n",
        "!pip install numpy==1.24.4  # Critical for CatBoost compatibility\n",
        "!pip install catboost==1.2.7\n",
        "!pip install tensorflow==2.12.0  # Optional (if you need TF)\n",
        "\n",
        "# Force restart the runtime (essential!)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # Or manually restart via Colab's UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxUzfGHGrdjl"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MiZXSGfrlsM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llEHp7_XsjnR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('CRACK DETECTION TRAIL FEB 2025.xlsx')\n",
        "\n",
        "X = df.drop(columns=['Conductance At FAILURE']).values\n",
        "y = df['Conductance At FAILURE'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "X_pca = pca.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_threshold = 0.7\n",
        "Target_mean = df['Conductance At FAILURE'].mean()\n",
        "Target_std = df['Conductance At FAILURE'].std()\n",
        "print(f\" At FAILURE Mean: {Target_mean}\")\n",
        "print(f\"Conductance At FAILURE Deviation: {Target_std}\")\n",
        "adjusted_threshold = Target_mean + Target_std\n",
        "\n",
        "y_binary = np.where(y > adjusted_threshold, 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_binary, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2_u8mJFM8PNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6wWKxEBs21h"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU5-j7Hks772"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64)(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "encoded = Dense(encoding_dim, activation=\"linear\")(x)  # Bottleneck layer\n",
        "\n",
        "x = Dense(32)(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dense(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "decoded = Dense(input_dim, activation=\"linear\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtfOp5x9tI3b"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(input_layer, decoded)\n",
        "encoder = Model(input_layer, encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InUf66yvtPvU"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=16, shuffle=True, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9H_O8cPtY37"
      },
      "outputs": [],
      "source": [
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iih2Sv0ItjuA"
      },
      "outputs": [],
      "source": [
        "catboost_model = CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.03, loss_function='Logloss', verbose=100)\n",
        "catboost_model.fit(X_train_encoded, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: classification table\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = catboost_model.predict(X_test_encoded)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "aeMkvjI69MS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: roc curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "y_pred_proba = catboost_model.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6UDb-ZHo9bT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual Values', marker='o')\n",
        "plt.plot(y_pred, label='Predicted Values', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3tipQ308-T0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give cracked value and predict crack or not from the model\n",
        "\n",
        "import numpy as np\n",
        "# Assuming 'cracked_value' is a single data point or an array of data points\n",
        "# that needs to be preprocessed (scaled and PCA-transformed) in the same way as the training data.\n",
        "\n",
        "\n",
        "# cracked_value should have the same number of features as the original data (11 in this case)\n",
        "cracked_value = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]]) # Example: Adjusted cracked_value with 11 features. Replace with your actual cracked value ensuring it has the correct number of features\n",
        "\n",
        "\n",
        "# Preprocess the cracked value\n",
        "cracked_value_scaled = scaler.transform(cracked_value)\n",
        "cracked_value_pca = pca.transform(cracked_value_scaled)\n",
        "\n",
        "# Encode using the trained encoder\n",
        "cracked_value_encoded = encoder.predict(cracked_value_pca)\n",
        "\n",
        "# Predict using the trained CatBoost model\n",
        "prediction = catboost_model.predict(cracked_value_encoded)\n",
        "\n",
        "\n",
        "# Interpretation\n",
        "if prediction[0] == 1:\n",
        "  print(\"The model predicts a crack.\")\n",
        "else:\n",
        "  print(\"The model predicts no crack.\")"
      ],
      "metadata": {
        "id": "XTHq9Kng-VfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print classification matrix with labels\\\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Assuming y_test and y_pred are defined as before\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels (replace with your actual labels)\n",
        "class_names = ['No Crack', 'Crack']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "# Show all ticks and label them with the respective list entries\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=class_names, yticklabels=class_names,\n",
        "       title='Confusion Matrix',\n",
        "       ylabel='True label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L_rB-AfZ_m4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPC"
      ],
      "metadata": {
        "id": "Zn0CbEk5_49N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('PPC CRACK DETECTION 2025.xlsx')\n",
        "\n",
        "X = df.drop(columns=['FAILURE']).values\n",
        "y = df['FAILURE'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "X_pca = pca.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "_TAptLu7_6-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_threshold = 0.7\n",
        "Target_mean = df['FAILURE'].mean()\n",
        "Target_std = df['FAILURE'].std()\n",
        "print(f\" At FAILURE Mean: {Target_mean}\")\n",
        "print(f\"Conductance At FAILURE Deviation: {Target_std}\")\n",
        "adjusted_threshold = Target_mean + Target_std\n",
        "\n",
        "y_binary = np.where(y > adjusted_threshold, 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_binary, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TAJxNf_HBuEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 16"
      ],
      "metadata": {
        "id": "wPyCR67jB5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64)(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "encoded = Dense(encoding_dim, activation=\"linear\")(x)  # Bottleneck layer\n",
        "\n",
        "x = Dense(32)(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dense(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "decoded = Dense(input_dim, activation=\"linear\")(x)"
      ],
      "metadata": {
        "id": "gJz64vu5CQsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(input_layer, decoded)\n",
        "encoder = Model(input_layer, encoded)"
      ],
      "metadata": {
        "id": "F_wy8HtcCXIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=16, shuffle=True, validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "id": "dSiXQ_2ICgwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)"
      ],
      "metadata": {
        "id": "uz1zjTaMCtja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.03, loss_function='Logloss', verbose=100)\n",
        "catboost_model.fit(X_train_encoded, y_train)"
      ],
      "metadata": {
        "id": "l7cYsC7jC2V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: classification table\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = catboost_model.predict(X_test_encoded)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "9N6IqKefC-xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: roc curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "y_pred_proba = catboost_model.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D3-zkab0DEJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual Values', marker='o')\n",
        "plt.plot(y_pred, label='Predicted Values', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E3egP-EKDKG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give cracked value and predict crack or not from the model\n",
        "\n",
        "import numpy as np\n",
        "# Assuming 'cracked_value' is a single data point or an array of data points\n",
        "# that needs to be preprocessed (scaled and PCA-transformed) in the same way as the training data.\n",
        "\n",
        "\n",
        "# cracked_value should have the same number of features as the original data (11 in this case)\n",
        "cracked_value = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 7.8, 0.9, 1.0, 1.1]]) # Example: Adjusted cracked_value with 11 features. Replace with your actual cracked value ensuring it has the correct number of features\n",
        "\n",
        "\n",
        "# Preprocess the cracked value\n",
        "cracked_value_scaled = scaler.transform(cracked_value)\n",
        "cracked_value_pca = pca.transform(cracked_value_scaled)\n",
        "\n",
        "# Encode using the trained encoder\n",
        "cracked_value_encoded = encoder.predict(cracked_value_pca)\n",
        "\n",
        "# Predict using the trained CatBoost model\n",
        "prediction = catboost_model.predict(cracked_value_encoded)\n",
        "\n",
        "\n",
        "# Interpretation\n",
        "if prediction[0] == 1:\n",
        "  print(\"The model predicts a crack.\")\n",
        "else:\n",
        "  print(\"The model predicts no crack.\")"
      ],
      "metadata": {
        "id": "pr2VPPBBDXOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print classification matrix with labels\\\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Assuming y_test and y_pred are defined as before\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels (replace with your actual labels)\n",
        "class_names = ['No Crack', 'Crack']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "# Show all ticks and label them with the respective list entries\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=class_names, yticklabels=class_names,\n",
        "       title='Confusion Matrix',\n",
        "       ylabel='True label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o3-BSVbYDjlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FRC"
      ],
      "metadata": {
        "id": "I0xZ0nsIDqD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel('PPC CRACK DETECTION 2025.xlsx')\n",
        "\n",
        "X = df.drop(columns=['FAILURE']).values\n",
        "y = df['FAILURE'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "X_pca = pca.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "0JggJBQvDs5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_threshold = 0.7\n",
        "Target_mean = df1['FAILURE'].mean()\n",
        "Target_std = df1['FAILURE'].std()\n",
        "print(f\" At FAILURE Mean: {Target_mean}\")\n",
        "print(f\"Conductance At FAILURE Deviation: {Target_std}\")\n",
        "adjusted_threshold = Target_mean + Target_std\n",
        "\n",
        "y_binary = np.where(y > adjusted_threshold, 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_binary, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lD2yF-TMEDQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 16"
      ],
      "metadata": {
        "id": "DKG_meyZEURv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64)(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "encoded = Dense(encoding_dim, activation=\"linear\")(x)  # Bottleneck layer\n",
        "\n",
        "x = Dense(32)(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dense(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "decoded = Dense(input_dim, activation=\"linear\")(x)"
      ],
      "metadata": {
        "id": "8orKy69-EjRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(input_layer, decoded)\n",
        "encoder = Model(input_layer, encoded)"
      ],
      "metadata": {
        "id": "tSuYdtwQEsgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=16, shuffle=True, validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "id": "6IeQtgNYE7wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)"
      ],
      "metadata": {
        "id": "J9irsfZGFLGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.03, loss_function='Logloss', verbose=100)\n",
        "catboost_model.fit(X_train_encoded, y_train)"
      ],
      "metadata": {
        "id": "0T-cXfThFRSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: classification table\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = catboost_model.predict(X_test_encoded)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "CwATzvjMFYXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: roc curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "y_pred_proba = catboost_model.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w1XTcoviFnuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual Values', marker='o')\n",
        "plt.plot(y_pred, label='Predicted Values', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n6AAkDBfGI_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give random cracked value, predict crack or not from model\n",
        "\n",
        "import numpy as np\n",
        "# Assuming 'cracked_value' is a single data point or an array of data points\n",
        "# that needs to be preprocessed (scaled and PCA-transformed) in the same way as the training data.\n",
        "\n",
        "# Example:  A random cracked value with 11 features.\n",
        "# Replace with your actual cracked value.\n",
        "cracked_value = np.random.rand(1, 11)\n",
        "\n",
        "# Preprocess the cracked value\n",
        "cracked_value_scaled = scaler.transform(cracked_value)\n",
        "cracked_value_pca = pca.transform(cracked_value_scaled)\n",
        "\n",
        "# Encode using the trained encoder\n",
        "cracked_value_encoded = encoder.predict(cracked_value_pca)\n",
        "\n",
        "# Predict using the trained CatBoost model\n",
        "prediction = catboost_model.predict(cracked_value_encoded)\n",
        "\n",
        "# Interpretation\n",
        "if prediction[0] == 1:\n",
        "  print(\"The model predicts a crack.\")\n",
        "else:\n",
        "  print(\"The model predicts no crack.\")\n"
      ],
      "metadata": {
        "id": "PUkLurYGGVUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: bar plot between crack and non cracked values\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_test and y_pred are already defined from your model's predictions\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Count cracked and non-cracked instances in y_test and y_pred\n",
        "cracked_actual = sum(y_test)\n",
        "non_cracked_actual = len(y_test) - cracked_actual\n",
        "cracked_predicted = sum(y_pred)\n",
        "non_cracked_predicted = len(y_pred) - cracked_predicted\n",
        "\n",
        "# Create the bar plot\n",
        "categories = ['Cracked', 'Non-Cracked']\n",
        "actual_values = [cracked_actual, non_cracked_actual]\n",
        "predicted_values = [cracked_predicted, non_cracked_predicted]\n",
        "\n",
        "x = range(len(categories))\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x, actual_values, width, label='Actual')\n",
        "rects2 = ax.bar([i + width for i in x], predicted_values, width, label='Predicted')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Actual vs. Predicted Crack Counts')\n",
        "ax.set_xticks([i + width / 2 for i in x])\n",
        "ax.set_xticklabels(categories)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aMqE0ECIGmRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}